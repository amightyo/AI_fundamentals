{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copy your Cognitive Service Key (`cognitive_key`) and Service Region (`cognitive_service_region`) to the variables listed below."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cognitive_key = '<YourKey>'\r\n",
        "cognitive_service_region = '<YourRegion>'\r\n",
        "\r\n",
        "print('Cognitive services ready at {}'.format(cognitive_service_region))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cognitive services ready at centralus\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1613994183848
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install Azure Speech SDK"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure.cognitiveservices.speech"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure.cognitiveservices.speech\n",
            "  Using cached azure_cognitiveservices_speech-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (3.1 MB)\n",
            "Installing collected packages: azure.cognitiveservices.speech\n",
            "Successfully installed azure.cognitiveservices.speech\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613917966358
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Translation\r\n",
        "\r\n",
        "You might remember that Text Translation API did not have a Python SDK. In the sample code below we have all the parameters, headers and the HTTP request body ready for you. \r\n",
        "Except two details. \r\n",
        "- First, we need you to add Italien into the list of target languages for our translation. You will need to play with the parameters to do that. \r\n",
        "- Second, we need you to complete the code between the green commented lines and make things work.   \r\n",
        "\r\n",
        "Go!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, uuid, json\r\n",
        "\r\n",
        "endpoint = \"https://api.cognitive.microsofttranslator.com/translate\"\r\n",
        "\r\n",
        "params = {\r\n",
        "    'api-version': '3.0',\r\n",
        "    'from': 'en',\r\n",
        "    'to': ['de']\r\n",
        "}\r\n",
        "\r\n",
        "headers = {\r\n",
        "    'Ocp-Apim-Subscription-Key': cognitive_key,\r\n",
        "    'Ocp-Apim-Subscription-Region': cognitive_service_region,\r\n",
        "    'Content-type': 'application/json',\r\n",
        "    'X-ClientTraceId': str(uuid.uuid4())\r\n",
        "}\r\n",
        "\r\n",
        "body = [{\r\n",
        "    'text': 'Hello World!'\r\n",
        "}]\r\n",
        "\r\n",
        "# YOUR CODE STARTS HERE #\r\n",
        "\r\n",
        "\r\n",
        "#YOUR CODE ENDS HERE #\r\n",
        "response = request.json()\r\n",
        "\r\n",
        "print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"translations\": [\n",
            "            {\n",
            "                \"text\": \"Hallo Welt!\",\n",
            "                \"to\": \"de\"\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"Salve, mondo!\",\n",
            "                \"to\": \"it\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613994938971
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample Output\r\n",
        "\r\n",
        "```\r\n",
        "[\r\n",
        "    {\r\n",
        "        \"translations\": [\r\n",
        "            {\r\n",
        "                \"text\": \"Hallo Welt!\",\r\n",
        "                \"to\": \"de\"\r\n",
        "            },\r\n",
        "            {\r\n",
        "                \"text\": \"Salve, mondo!\",\r\n",
        "                \"to\": \"it\"\r\n",
        "            }\r\n",
        "        ]\r\n",
        "    }\r\n",
        "]\r\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Speech Translation\r\n",
        "\r\n",
        "We are given a `speech-sample.wav` file with some speech in it that has to be converted to German and French. If I were in your shoes I would start preparing a Translation Config and an Audio Config objects first. \r\n",
        "Those can help to initialize a `TranslationRecognizer` and run the audio file through the translation process. You can find a sample output after Cell 3. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azure.cognitiveservices.speech as speechsdk\r\n",
        "\r\n",
        "# YOUR CODE STARTS HERE #\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#YOUR CODE ENDS HERE #\r\n",
        "\r\n",
        "if result.reason == speechsdk.ResultReason.TranslatedSpeech:\r\n",
        "    print(\"\"\"Recognized: {}\r\n",
        "    German translation: {}\r\n",
        "    French translation: {}\"\"\".format(\r\n",
        "        result.text, result.translations['de'], result.translations['fr']))\r\n",
        "elif result.reason == speechsdk.ResultReason.RecognizedSpeech:\r\n",
        "    print(\"Recognized: {}\".format(result.text))\r\n",
        "elif result.reason == speechsdk.ResultReason.NoMatch:\r\n",
        "    print(\"No speech could be recognized: {}\".format(result.no_match_details))\r\n",
        "elif result.reason == speechsdk.ResultReason.Canceled:\r\n",
        "    print(\"Translation canceled: {}\".format(result.cancellation_details.reason))\r\n",
        "    if result.cancellation_details.reason == speechsdk.CancellationReason.Error:\r\n",
        "        print(\"Error details: {}\".format(result.cancellation_details.error_details))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: This is me talking to see how Azure Cognitive Services does speech recognition.\n",
            "    German translation: Dies ist ein Gespräch, um zu sehen, wie Azure Cognitive Services Spracherkennung macht.\n",
            "    French translation: C’est moi qui parle pour voir comment Azure Cognitive Services fait la reconnaissance vocale.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613994193758
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample Output\r\n",
        "```\r\n",
        "Recognized: This is me talking to see how Azure Cognitive Services does speech recognition.\r\n",
        "    German translation: Dies ist ein Gespräch, um zu sehen, wie Azure Cognitive Services Spracherkennung macht.\r\n",
        "    French translation: C’est moi qui parle pour voir comment Azure Cognitive Services fait la reconnaissance vocale.\r\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good work!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}