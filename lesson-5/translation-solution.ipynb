{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copy your Cognitive Service Key (`cognitive_key`) and Service Region (`cognitive_service_region`) to the variables listed below."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cognitive_key = '<YourKey>'\r\n",
        "cognitive_service_region = '<YourRegion>'\r\n",
        "\r\n",
        "print('Cognitive services ready at {}'.format(cognitive_service_region))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cognitive services ready at centralus\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1613994183848
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install Azure Speech SDK"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure.cognitiveservices.speech"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure.cognitiveservices.speech\n",
            "  Using cached azure_cognitiveservices_speech-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (3.1 MB)\n",
            "Installing collected packages: azure.cognitiveservices.speech\n",
            "Successfully installed azure.cognitiveservices.speech\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613917966358
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Translation\r\n",
        "\r\n",
        "We have to submit an HTTP request to use the Text Translation API, as there is no Python SDK for this service. We are submitting the parameters, headers, and the JSON body for our text to get back a JSON that contains all the translations."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, uuid, json\r\n",
        "\r\n",
        "endpoint = \"https://api.cognitive.microsofttranslator.com/translate\"\r\n",
        "\r\n",
        "params = {\r\n",
        "    'api-version': '3.0',\r\n",
        "    'from': 'en',\r\n",
        "    'to': ['de', 'it']\r\n",
        "}\r\n",
        "\r\n",
        "headers = {\r\n",
        "    'Ocp-Apim-Subscription-Key': cognitive_key,\r\n",
        "    'Ocp-Apim-Subscription-Region': cognitive_service_region,\r\n",
        "    'Content-type': 'application/json',\r\n",
        "    'X-ClientTraceId': str(uuid.uuid4())\r\n",
        "}\r\n",
        "\r\n",
        "body = [{\r\n",
        "    'text': 'Hello World!'\r\n",
        "}]\r\n",
        "\r\n",
        "request = requests.post(endpoint, params=params, headers=headers, json=body)\r\n",
        "response = request.json()\r\n",
        "\r\n",
        "print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"translations\": [\n",
            "            {\n",
            "                \"text\": \"Hallo Welt!\",\n",
            "                \"to\": \"de\"\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"Salve, mondo!\",\n",
            "                \"to\": \"it\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613994938971
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Speech Translation\r\n",
        "\r\n",
        "We are given a `speech-sample.wav` file with some speech in it that has to be converted to German and French. First, we have to create a **Translation Config** object that includes our service access key and region, the original recognition language,\r\n",
        "and finally, the target languages that we want the speech to be converted. Once our **Translation Config** is ready, we are setting up an **Audio Config** that points out our `speech-sample.wav` file as the translation source. Finally, we are initializing a **Recognizer** \r\n",
        "by passing the two configuration objects to `speechsdk.translation.TranslationRecognizer`. Calling the `recognize_once()` gets us a recognized text and its translation to all languages we have requested."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azure.cognitiveservices.speech as speechsdk\r\n",
        "\r\n",
        "translation_config = speechsdk.translation.SpeechTranslationConfig(\r\n",
        "        subscription=cognitive_key, region=cognitive_service_region,\r\n",
        "        speech_recognition_language='en-US',\r\n",
        "        target_languages=('de', 'fr'))\r\n",
        "audio_config = speechsdk.audio.AudioConfig(filename=\"speech-sample.wav\")\r\n",
        "\r\n",
        "recognizer = speechsdk.translation.TranslationRecognizer(\r\n",
        "    translation_config=translation_config, audio_config=audio_config)\r\n",
        "\r\n",
        "result = recognizer.recognize_once()\r\n",
        "\r\n",
        "if result.reason == speechsdk.ResultReason.TranslatedSpeech:\r\n",
        "    print(\"\"\"Recognized: {}\r\n",
        "    German translation: {}\r\n",
        "    French translation: {}\"\"\".format(\r\n",
        "        result.text, result.translations['de'], result.translations['fr']))\r\n",
        "elif result.reason == speechsdk.ResultReason.RecognizedSpeech:\r\n",
        "    print(\"Recognized: {}\".format(result.text))\r\n",
        "elif result.reason == speechsdk.ResultReason.NoMatch:\r\n",
        "    print(\"No speech could be recognized: {}\".format(result.no_match_details))\r\n",
        "elif result.reason == speechsdk.ResultReason.Canceled:\r\n",
        "    print(\"Translation canceled: {}\".format(result.cancellation_details.reason))\r\n",
        "    if result.cancellation_details.reason == speechsdk.CancellationReason.Error:\r\n",
        "        print(\"Error details: {}\".format(result.cancellation_details.error_details))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized: This is me talking to see how Azure Cognitive Services does speech recognition.\n",
            "    German translation: Dies ist ein Gespräch, um zu sehen, wie Azure Cognitive Services Spracherkennung macht.\n",
            "    French translation: C’est moi qui parle pour voir comment Azure Cognitive Services fait la reconnaissance vocale.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613994193758
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good work!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}